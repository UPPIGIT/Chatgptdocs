{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# \ud83e\uddea NLP Preprocessing + Classification (Logistic Regression)\n",
        "\n",
        "This notebook covers:\n",
        "- Text preprocessing (cleaning, tokenizing, lemmatizing, etc.)\n",
        "- TF-IDF vectorization\n",
        "- Sentiment classification using Logistic Regression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# \u2705 Step 1: Install & Import Libraries\n",
        "!pip install nltk scikit-learn textblob pandas --quiet\n",
        "\n",
        "import pandas as pd\n",
        "import string\n",
        "import re\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# \u2705 Step 2: Sample Dataset\n",
        "data = {\n",
        "    \"review\": [\n",
        "        \"I loved the movie, it was amazing!\",\n",
        "        \"Terrible movie, I hated it.\",\n",
        "        \"It was an okay movie, not bad.\",\n",
        "        \"Absolutely fantastic acting and story.\",\n",
        "        \"Waste of time, very boring.\",\n",
        "        \"Best movie I've seen in years!\",\n",
        "        \"Not worth watching, very poor.\"\n",
        "    ],\n",
        "    \"label\": [1, 0, 1, 1, 0, 1, 0]  # 1 = positive, 0 = negative\n",
        "}\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# \u2705 Step 3: Preprocessing Function\n",
        "stop_words = set(stopwords.words('english'))\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "def preprocess(text):\n",
        "    text = text.lower()\n",
        "    text = re.sub(r'\\d+', '', text)\n",
        "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
        "    tokens = nltk.word_tokenize(text)\n",
        "    tokens = [lemmatizer.lemmatize(word) for word in tokens if word not in stop_words]\n",
        "    return ' '.join(tokens)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# \u2705 Step 4: Apply Preprocessing\n",
        "df['clean_review'] = df['review'].apply(preprocess)\n",
        "df[['review', 'clean_review', 'label']]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# \u2705 Step 5: Train/Test Split\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    df['clean_review'], df['label'], test_size=0.3, random_state=42\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# \u2705 Step 6: Vectorization\n",
        "vectorizer = TfidfVectorizer()\n",
        "X_train_vec = vectorizer.fit_transform(X_train)\n",
        "X_test_vec = vectorizer.transform(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# \u2705 Step 7: Train Classifier\n",
        "model = LogisticRegression()\n",
        "model.fit(X_train_vec, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# \u2705 Step 8: Evaluate\n",
        "y_pred = model.predict(X_test_vec)\n",
        "print(classification_report(y_test, y_pred))"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}